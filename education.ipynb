{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading in data sets \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "_1718 =pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\Disag_2017-18_Data.txt\", sep='\\t',dtype={'school_code':object, 'name':object, 'grade_span':object, 'subject':object, 'grade':object, 'type':object, 'subgroup':object, 'num_tested':float, 'pct_l1':object, 'pct_l2':object, 'pct_l3':object, 'pct_l4':object, 'pct_l5':object, 'pct_ccr':object, 'pct_glp':object, 'avg_score':float})     \n",
    "_1617 =pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\Disag_2016-17_Data.txt\", sep='\\t',dtype={'school_code':object, 'name':object, 'grade_span':object, 'subject':object, 'grade':object, 'type':object, 'subgroup':object, 'num_tested':float, 'num_l1':object, 'pct_l1':object, 'num_l2':object, 'pct_l2':object, 'num_l3':object, 'pct_l3':object, 'num_l4':object, 'pct_l4':object, 'num_l5':object, 'pct_l5':object, 'num_ccr':object, 'pct_ccr':object, 'num_glp':object, 'pct_glp':object})     \n",
    "_1516 =pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\Disag_2015-16_Data.txt\", sep='\\t',dtype={'school_code':object, 'name':object, 'grade_span':object, 'subject':object, 'grade':object, 'type':object, 'subgroup':object, 'num_tested':float, 'num_l1':object, 'pct_l1':object, 'num_l2':object, 'pct_l2':object, 'num_l3':object, 'pct_l3':object, 'num_l4':object, 'pct_l4':object, 'num_l5':object, 'pct_l5':object, 'num_ccr':object, 'pct_ccr':object, 'num_glp':object, 'pct_glp':object})     \n",
    "_1415 =pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\Disag_2014-15_Data.txt\", sep='\\t',dtype={'school_code':object, 'name':object, 'grade_span':object, 'subject':object, 'grade':object, 'type':object, 'subgroup':object, 'num_tested':float, 'num_l1':object, 'pct_l1':object, 'num_l2':object, 'pct_l2':object, 'num_l3':object, 'pct_l3':object, 'num_l4':object, 'pct_l4':object, 'num_l5':object, 'pct_l5':object, 'num_ccr':object, 'pct_ccr':object, 'num_glp':object, 'pct_glp':object})     \n",
    "_1314 =pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\Disag_2013-14_Data.txt\", sep='\\t',dtype={'school_code':object, 'name':object, 'grade_span':object, 'subject':object, 'grade':object, 'type':object, 'subgroup':object, 'num_tested':float, 'num_l1':object, 'pct_l1':object, 'num_l2':object, 'pct_l2':object, 'num_l3':object, 'pct_l3':object, 'num_l4':object, 'pct_l4':object, 'num_l5':object, 'pct_l5':object, 'num_ccr':object, 'pct_ccr':object, 'num_glp':object, 'pct_glp':object})     \n",
    "school=pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\school.txt\", sep='\\t',dtype={'school_code':str,'grade_span':object,'school_name':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding years to the dataset\n",
    "_1718['year']=2017\n",
    "_1617['year']=2016\n",
    "_1516['year']=2015\n",
    "_1415['year']=2014\n",
    "_1314['year']=2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set all data on top of each other\n",
    "\n",
    "data=_1718.append(_1617.append(_1516.append(_1415.append(_1314))))\n",
    "data=data.replace(['*','<'],'0')\n",
    "data.fillna(0 ,inplace = True)\n",
    "school.fillna(0 ,inplace = True)\n",
    "\n",
    "#dropped columns i didnt want\n",
    "\n",
    "data=data.drop(['grade_span','avg_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merged on school_code and made prefix numbers to merge on districts\n",
    "\n",
    "data1=pd.merge(data, school, on=['school_code'])\n",
    "data1['school_prefix_number']=data1['school_code'].astype(str).str[:3]\n",
    "data1['school_suffix_number']=data1['school_code'].astype(str).str[3:6]\n",
    "data1['school_prefix_number2']=data1['school_prefix_number'].astype(str).str[:2]\n",
    "data1.fillna('none',inplace=True)\n",
    "\n",
    "#get rid of NC- prefixes, they are SBE districts that we don't need\n",
    "\n",
    "data1=data1[data1['school_prefix_number'] !='NC-' ]\n",
    "\n",
    "# data takes to long to run with all subgroups and types so I narrowed it down to just all\n",
    "\n",
    "data1=data1[data1['subgroup'] =='ALL' ]\n",
    "data1=data1[data1['type'] =='ALL' ]\n",
    "data1=data1[data1['grade'] =='ALL' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading in district data sets\n",
    "\n",
    "public=pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\public.txt\",sep='\\t',dtype={'school_prefix_number':object,'district_name':str,'phone':object})\n",
    "charter=pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\charter.csv\", dtype={'district_name':str,'school_prefix_number':object,'phone':object})\n",
    "county=pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\proj\\county.txt\",sep='\\t',dtype={'district_name':str,'City':object,'County name':object})\n",
    "\n",
    "#appended charter and public school district datasets together\n",
    "\n",
    "district=public.append(charter)\n",
    "\n",
    "#create a way to make district names match county district names \n",
    "\n",
    "district['district_name']=district['district_name'].str.replace(r\"(Schools)\",r\"School District \")\n",
    "district['district_name']=district['district_name'].str.replace(r\"(Academy)\",r\"Academy School District \")\n",
    "\n",
    "# removed trailing spaces\n",
    "\n",
    "district['district_name']=district['district_name'].map(lambda x: x.strip())\n",
    "county['district_name']=county['district_name'].map(lambda x: x.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged districts and county data on district names and created prefix2 for code for all distinct counties\n",
    "\n",
    "district1=pd.merge(district, county, on=['district_name'],how='left')\n",
    "district1['school_prefix_number2']=district1['school_prefix_number'].astype(str).str[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create district 2 dataframe with the unique county school prefixes and the name of those counties.\n",
    "\n",
    "district2=district1\n",
    "district2=district2.drop(['phone','City ','school_prefix_number'],axis=1)\n",
    "district1=district1.drop(['County name','district_name'],axis=1)\n",
    "district2=district2.dropna(subset=['County name'])\n",
    "district2=district2.drop_duplicates(subset=['school_prefix_number2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging counties onto the districts for all districts, \n",
    "\n",
    "#county prefix 99 is still a little messed up it has multiple counties on it.\n",
    "\n",
    "district3=pd.merge(district1,district2,on=['school_prefix_number2'])\n",
    "district3.to_csv('district.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#left merged data1 on to district to put each school into their county\n",
    "\n",
    "data2=pd.merge(data1,district3, on=['school_prefix_number2'],how='left')\n",
    "data2.loc[data2['school_prefix_number_x'] == '590', 'County name'] = 'McDowell'\n",
    "data2.loc[data2['school_prefix_number_x'] == '995', 'County name'] = 'Yancey'\n",
    "data2.loc[data2['school_prefix_number_x'] >= '996', 'County name'] = 'State'\n",
    "\n",
    "data2.loc[data2['school_prefix_number_x'] == '590', 'district_name'] = 'McDowell County School District'\n",
    "data2.loc[data2['school_prefix_number_x'] == '995', 'district_name'] = 'Yancey County School District'\n",
    "data2.loc[data2['school_prefix_number_x'] >= '996', 'district_name'] = 'State School District'\n",
    "data2['school_prefix_number']=data2['school_prefix_number_x']\n",
    "data2=data2.drop(['grade_span','school_prefix_number_x','school_prefix_number_y','City ','phone','name','num_l1','num_l2','num_l3','num_l4','num_l5'],axis=1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     0\n",
       "unique    0\n",
       "Name: County name, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing if there is any missing counties \n",
    "\n",
    "man=data2[data2['County name']=='']\n",
    "man['County name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2=data2[data2['school_prefix_number'] !='298' ]\n",
    "data2=data2[data2['school_suffix_number'] !='LEA' ]\n",
    "\n",
    "#put in city districts\n",
    "\n",
    "data2.loc[data2['school_prefix_number'] == '111', 'district_name'] = 'Asheville City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '132', 'district_name'] = 'Kannapolis City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '181', 'district_name'] = 'Hickory City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '182', 'district_name'] = 'Newton Conover City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '241', 'district_name'] = 'Whiteville City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '291', 'district_name'] = 'Lexington City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '292', 'district_name'] = 'Thomasville City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '421', 'district_name'] = 'Roanoke Rapids City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '422', 'district_name'] = 'Weldon City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '491', 'district_name'] = 'Mooresville Graded School District'\n",
    "data2.loc[data2['school_prefix_number'] == '681', 'district_name'] = 'Chapel Hill-Carrboro City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '761', 'district_name'] = 'Asheboro City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '821', 'district_name'] = 'Clinton City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '861', 'district_name'] = 'Elkin City School District'\n",
    "data2.loc[data2['school_prefix_number'] == '862', 'district_name'] = 'Mount Airy City School District'\n",
    "\n",
    "data2=data2.drop_duplicates(subset=['year','school_name','pct_glp','num_tested','subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data2.replace('<5','5')\n",
    "data2=data2.replace('>95','95')\n",
    "\n",
    "data2['num_tested']=data2['num_tested'].astype(int)\n",
    "data2['pct_ccr']=data2['pct_ccr'].astype(float)\n",
    "data2['pct_glp']=data2['pct_glp'].astype(float)\n",
    "data2=data2.drop(['pct_l1','pct_l2','pct_l3','pct_l4','pct_l5','num_ccr','num_glp','school_suffix_number','school_prefix_number2','school_prefix_number'],axis=1)      \n",
    "data2.to_csv('data.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
